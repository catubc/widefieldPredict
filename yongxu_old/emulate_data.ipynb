{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") # Adds higher directory to python modules path.\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import torch\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from locanmf import LocaNMF\n",
    "import postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 16384)\n",
      "(1801, 132, 7)\n",
      "(1801, 132, 16384)\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "res = None\n",
    "\n",
    "spatial = np.load('/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_trial_ROItimeCourses_30sec_pca_0.95_spatial.npy')\n",
    "print (spatial.shape)\n",
    "\n",
    "temporal = np.load('/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_trial_ROItimeCourses_30sec_pca_0.95.npy')\n",
    "temporal = temporal.transpose(2,0,1)\n",
    "print (temporal.shape)\n",
    "\n",
    "res = np.matmul(temporal, spatial)\n",
    "print (res.shape)\n",
    "print (\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 1801, 16384)\n",
      "(132, 1801, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "res2 = res.transpose(1,0,2)\n",
    "print (res2.shape)\n",
    "\n",
    "res2 = res2.reshape(res2.shape[0], \n",
    "                    res2.shape[1], \n",
    "                    128, 128)\n",
    "print (res2.shape)\n",
    "\n",
    "res2_mean = res2.mean(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/132 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1801, 128, 128)\n",
      "(900, 128, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 132/132 [01:00<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "#\n",
    "\n",
    "print (res2_mean.shape)\n",
    "res2_half = res2_mean[:res2_mean.shape[0]//2]\n",
    "print (res2_half.shape)\n",
    "    \n",
    "# \n",
    "mu = 0\n",
    "sigma = 0.05\n",
    "\n",
    "# \n",
    "res_sim = np.zeros((132, res2_half.shape[0],\n",
    "                    res2_half.shape[1],\n",
    "                    res2_half.shape[2]), 'float32')\n",
    "\n",
    "# \n",
    "for p in trange(res_sim.shape[0]):\n",
    "    noise = np.random.normal(mu, sigma, size=res2_half.shape) \n",
    "    temp = res2_half + noise\n",
    "    res_sim[p] = temp\n",
    "    \n",
    "np.save('/home/cat/res_sim'+str(sigma)+'.npy', res_sim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# load PCA pbject\n",
    "import pickle as pk\n",
    "fname_pca = '/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_trial_ROItimeCourses_30sec_pca.pkl'\n",
    "file = open(fname_pca, 'rb')\n",
    "pca = pk.load(file)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 900, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# res_sim = np.load('/home/cat/res_sim.npy')\n",
    "# print (res_sim.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (118800, 16384)\n",
      "(118800, 1500)\n"
     ]
    }
   ],
   "source": [
    "X = res_sim.reshape(132*900, 128*128)\n",
    "print (\"X: \", X.shape)\n",
    "\n",
    "time_filters = pca.transform(X)#[:,:nComp]\n",
    "\n",
    "print (time_filters.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 7, 1801)\n"
     ]
    }
   ],
   "source": [
    "random = np.load('/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_random_ROItimeCourses_30sec_pca_0.95.npy')\n",
    "print (random.shape)\n",
    "\n",
    "np.save('/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_random_ROItimeCourses_30sec_pca_0.95_firsthalf.npy',\n",
    "       random[:,:,:900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 7, 1801)\n",
      "(132, 7, 900)\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "trials = np.load('/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_trial_ROItimeCourses_30sec_pca_0.95.npy')\n",
    "print (trials.shape)\n",
    "\n",
    "#\n",
    "nComp = 7\n",
    "res_pca = time_filters.reshape(132,900,-1)[:,:,:7].transpose(0,2,1)\n",
    "print (res_pca.shape)\n",
    "\n",
    "fname_out = '/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_trial_ROItimeCourses_30sec_pca_0.95_firsthalf.npy'\n",
    "np.save(fname_out.replace('trial','simulated'),\n",
    "       res_pca)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f:  (14745600,)\n",
      "idx:  (3528646,)\n",
      "(3528646,)\n"
     ]
    }
   ],
   "source": [
    "# #\n",
    "# width = 0.00001\n",
    "# bins = np.arange(-0.02,0.02,width)\n",
    "# f = res2_half.flatten()\n",
    "\n",
    "# # \n",
    "# print (\"f: \", f.shape)\n",
    "# idx = np.where(np.abs(f)<0.000001)[0]\n",
    "# print (\"idx: \", idx.shape)\n",
    "# f[idx]=np.nan\n",
    "# idx = np.where(np.isnan(f))[0]\n",
    "# print (idx.shape)\n",
    "\n",
    "# # \n",
    "# y = np.histogram(f, \n",
    "#                  bins=bins)\n",
    "\n",
    "# # \n",
    "# plt.plot(y[1][1:],y[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/900 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stacked trials :  (2, 132, 7, 900)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [13:23<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def run_10fold(k,\n",
    "               idx,\n",
    "               trials_window_flat,\n",
    "               ):\n",
    "\n",
    "    #\n",
    "    idx_test = idx[k]\n",
    "    X_test = trials_window_flat[:,idx_test]\n",
    "    y_test = []\n",
    "    for f in range(X_test.shape[0]):\n",
    "        y_test.append(np.zeros(X_test[f].shape[0])+f)\n",
    "        \n",
    "    # stack the data\n",
    "    y_test = np.hstack(y_test)\n",
    "    X_test = X_test.reshape(-1, X_test.shape[2])\n",
    "    #print (\"X_test: \", X_test.shape, \" y_test: \", y_test.shape)\n",
    "\n",
    "    #\n",
    "    idx_train = np.delete(np.arange(trials_window_flat.shape[1]), idx[k])\n",
    "    train = trials_window_flat[:,idx_train]\n",
    "    # print (\"Train: \", train.shape)\n",
    "\n",
    "    # loop over all features/body parts and generate labels\n",
    "    y_train = []\n",
    "    X_train = []\n",
    "    for f in range(train.shape[0]):\n",
    "        y_train.append(np.zeros(train[f].shape[0])+f)\n",
    "        X_train.append(train[f])\n",
    "\n",
    "    X_train = np.vstack(X_train)\n",
    "    y_train = np.hstack(y_train)\n",
    "    #print (\"X_train: \", X_train.shape, \" y_train: \", y_train.shape)\n",
    "\n",
    "    # STANDARDIZE DATA\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    #\n",
    "    # Fit SVM/Classifier\n",
    "\n",
    "    acc, svm_coef = run_svm_multi_variate(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    \n",
    "    return acc\n",
    "\n",
    "def run_svm_multi_variate(X_train, y_train, X_test, y_test):\n",
    "\n",
    "    #linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "    # s = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "    #poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "    s = svm.SVC(kernel='sigmoid',\n",
    "    #s = svm.SVC(kernel='linear',\n",
    "                C=1,\n",
    "                decision_function_shape='ovo').fit(X_train, y_train)\n",
    "\n",
    "    # retrieve the accuracy and print it for all 4 kernel functions\n",
    "    accuracy = s.score(X_test, y_test)\n",
    "    prediction = s.predict(X_test)\n",
    "\n",
    "    #\n",
    "    # print (\"s.coef_ \", s.coef_.shape, X_train.shape)\n",
    "    return accuracy, prediction\n",
    "\n",
    "\n",
    "# \n",
    "# load pca data\n",
    "trials = np.load('/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_simulated_ROItimeCourses_30sec_pca_0.95_firsthalf.npy')\n",
    "random = np.load('/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/IJ1pm_Mar3_30Hz_code_04_random_ROItimeCourses_30sec_pca_0.95_firsthalf.npy')\n",
    "all_trials = np.array((trials, random))\n",
    "print (\"stacked trials : \", all_trials.shape)\n",
    "\n",
    "#    \n",
    "from tqdm import trange\n",
    "import parmap\n",
    "acc_array = []\n",
    "for t in trange(0,900,1):\n",
    "    t = 0\n",
    "    window = 30\n",
    "    t1 = t\n",
    "    t2 = t + window\n",
    "\n",
    "    # \n",
    "    trials_window = all_trials[:,:,t1:t2]\n",
    "    #print (\"trials full in: \", all_trials.shape, \"trials window: \", trials_window.shape)\n",
    "\n",
    "    trials_window_flat = trials_window.reshape(trials_window.shape[0],\n",
    "                                               trials_window.shape[1],\n",
    "                                               -1)\n",
    "    #print (trials_window_flat.shape)\n",
    "\n",
    "    # 10-fold split; should we randomize?\n",
    "    idx = np.array_split(np.random.choice(np.arange(trials_window_flat.shape[1]),\n",
    "                                          trials_window_flat.shape[1], replace=False),\n",
    "                         10)\n",
    "\n",
    "    # \n",
    "    ks = np.arange(10)\n",
    "    if False:\n",
    "        \n",
    "        acc = parmap.map(run_10fold, ks,\n",
    "                  idx, \n",
    "                  trials_window_flat,\n",
    "                  pm_processes=10)\n",
    "    else:\n",
    "        acc= []\n",
    "        for k in range(10):\n",
    "            acc.append(run_10fold(k,\n",
    "                       idx,\n",
    "                       trials_window_flat,\n",
    "                      ))\n",
    "\n",
    "    acc_array.append(acc)\n",
    "\n",
    "# \n",
    "temp = np.array(acc_array)\n",
    "np.save('/media/cat/1TB/yuki/yongxu/locaNMF_data/data/IJ1/Mar3/svm_acc_simulated_0.005noise.npy', temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (temp.shape)\n",
    "\n",
    "mean = temp.mean(1)\n",
    "std = np.std(temp,1)\n",
    "\n",
    "t = np.arange(-900,0,1)/30\n",
    "plt.plot(t,mean)\n",
    "plt.ylim(0.4,1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
